{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cG5ozxkoKIB5Ka2NtioqAJdqXWfjiLiS",
      "authorship_tag": "ABX9TyMvRmQMQjGFSNV03NBkpIf0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AwaisAli37405/Deep_Learning/blob/master/DeepLearning_with_process_mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning with Process Mining\n",
        "\n",
        "- To access the event logs please give an access to the folder in your drive"
      ],
      "metadata": {
        "id": "5A8r3hYPhYy4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MjcGiwqbbWHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db066a0-2a66-45b2-92b6-032b70ef91ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "BPI_Challenge_2012_W_Two_TS.csv  confidential_2000.csv\t       insurance.csv\n",
            "BPI_Challenge_2017_W_Two_TS.csv  ConsultaDataMining201618.csv  Production.csv\n",
            "confidential_1000.csv\t\t cvs_pharmacy.csv\t       PurchasingExample.csv\n"
          ]
        }
      ],
      "source": [
        "# access the input folder in a google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# Specify the folder path\n",
        "folder_path = '/content/drive/MyDrive/Colab\\ Notebooks/event_logs/'\n",
        "\n",
        "# List the contents of the folder\n",
        "!ls {folder_path}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbj5oOrPhxaC",
        "outputId": "47dde88f-b05d-49d0-9c80-aa1364a0a18e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/event_logs/'\n",
        "files = os.listdir(folder_path)\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h74CCHKljO-X",
        "outputId": "8954bc82-9bd7-46f1-cfa1-44acc75c50ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ConsultaDataMining201618.csv', 'confidential_1000.csv', 'confidential_2000.csv', 'BPI_Challenge_2012_W_Two_TS.csv', 'insurance.csv', 'Production.csv', 'PurchasingExample.csv', 'cvs_pharmacy.csv', 'BPI_Challenge_2017_W_Two_TS.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Accessing the 'cvs_pharmacy.csv' file\n",
        "file_path = os.path.join(folder_path, 'cvs_pharmacy.csv')  # Assuming 'cvs_pharmacy.csv' is in 'event_logs' folder\n",
        "# Verify if the file exists before attempting to read it\n",
        "if os.path.exists(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Now you can work with the DataFrame 'df'\n",
        "    print(df.head())  # To see the output, run the code.\n",
        "else:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "    print(\"Please check the file path and ensure the file exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJrGMo0AjUPY",
        "outputId": "9daac0b0-8479-4b79-e093-317b01583949"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          task  caseid                    user  \\\n",
            "0   Enter prescription details    5320       Technician-000003   \n",
            "1   Check if refill is allowed    5320  Pharmacy System-000001   \n",
            "2                    Check DUR    5320  Pharmacy System-000001   \n",
            "3              Check Insurance    5320  Pharmacy System-000001   \n",
            "4  Pack the drugs (Production)    5320       Technician-000003   \n",
            "\n",
            "             LogType  case_variant                                 elementId  \\\n",
            "0  MXML.EnactmentLog             1  sid-B9F72F21-DC8A-4873-9E04-B19ED7381ADC   \n",
            "1  MXML.EnactmentLog             1  sid-0B0AE587-EE27-414E-A051-D91E1866E1C3   \n",
            "2  MXML.EnactmentLog             1  sid-2B439B6B-4DD1-4D40-902D-43B7C4F215AB   \n",
            "3  MXML.EnactmentLog             1  sid-D859AC4F-3984-4A6B-8366-62B226C4DD53   \n",
            "4  MXML.EnactmentLog             1  sid-A4A84A0D-A58B-4650-A3F2-D1967DB8C146   \n",
            "\n",
            "                                  processId  resourceCost  \\\n",
            "0  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987      0.963500   \n",
            "1  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987           NaN   \n",
            "2  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987           NaN   \n",
            "3  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987           NaN   \n",
            "4  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987      1.075431   \n",
            "\n",
            "                                 resourceId            end_timestamp  \\\n",
            "0  sid-C1BCD679-E133-4F46-9956-013E1F9E0BD1  2019-04-30T19:19:10.183   \n",
            "1  sid-66F243A5-4165-4803-805B-A5F6BB41B476  2019-04-30T19:19:10.183   \n",
            "2  sid-66F243A5-4165-4803-805B-A5F6BB41B476  2019-04-30T19:19:10.183   \n",
            "3  sid-66F243A5-4165-4803-805B-A5F6BB41B476  2019-04-30T19:19:10.183   \n",
            "4  sid-C1BCD679-E133-4F46-9956-013E1F9E0BD1  2019-05-02T12:28:14.988   \n",
            "\n",
            "           start_timestamp  \n",
            "0  2019-04-30T19:16:51.439  \n",
            "1  2019-04-30T19:19:10.183  \n",
            "2  2019-04-30T19:19:10.183  \n",
            "3  2019-04-30T19:19:10.183  \n",
            "4  2019-05-02T12:25:40.126  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Event Log Preprocessing"
      ],
      "metadata": {
        "id": "z6HAnsARkD9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# renamming the columns and replacing the actual resource and tasks with dummy values\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# 1. Rename columns\n",
        "column_mapping = {\n",
        "    'task': 'activity',\n",
        "    'user': 'resource',\n",
        "    'start_timestamp': 'start',\n",
        "    'end_timestamp':'end'\n",
        "}\n",
        "df = df.rename(columns=column_mapping)\n",
        "print(df.columns)\n",
        "\n",
        "# 2. Replace resource and task values with dummy values\n",
        "resource_column = 'resource'  # Replace with the actual column name\n",
        "task_column = 'activity'  # Replace with the actual column name\n",
        "\n",
        "# Create unique dummy values using dictionaries\n",
        "resource_mapping = {resource: f'Resource_{i+1}' for i, resource in enumerate(df[resource_column].unique())}\n",
        "task_mapping = {task: f'Task_{i+1}' for i, task in enumerate(df[task_column].unique())}\n",
        "\n",
        "# Replace values in the DataFrame\n",
        "df[resource_column] = df[resource_column].map(resource_mapping)\n",
        "df[task_column] = df[task_column].map(task_mapping)\n",
        "\n",
        "# Now 'df' has renamed columns and dummy values for resources and tasks\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVTiAzxIjYUE",
        "outputId": "38203bea-da0a-43af-ba8e-a52d4ab979cc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['activity', 'caseid', 'resource', 'LogType', 'case_variant',\n",
            "       'elementId', 'processId', 'resourceCost', 'resourceId', 'end', 'start'],\n",
            "      dtype='object')\n",
            "  activity  caseid    resource            LogType  case_variant  \\\n",
            "0   Task_1    5320  Resource_1  MXML.EnactmentLog             1   \n",
            "1   Task_2    5320  Resource_2  MXML.EnactmentLog             1   \n",
            "2   Task_3    5320  Resource_2  MXML.EnactmentLog             1   \n",
            "3   Task_4    5320  Resource_2  MXML.EnactmentLog             1   \n",
            "4   Task_5    5320  Resource_1  MXML.EnactmentLog             1   \n",
            "\n",
            "                                  elementId  \\\n",
            "0  sid-B9F72F21-DC8A-4873-9E04-B19ED7381ADC   \n",
            "1  sid-0B0AE587-EE27-414E-A051-D91E1866E1C3   \n",
            "2  sid-2B439B6B-4DD1-4D40-902D-43B7C4F215AB   \n",
            "3  sid-D859AC4F-3984-4A6B-8366-62B226C4DD53   \n",
            "4  sid-A4A84A0D-A58B-4650-A3F2-D1967DB8C146   \n",
            "\n",
            "                                  processId  resourceCost  \\\n",
            "0  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987      0.963500   \n",
            "1  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987           NaN   \n",
            "2  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987           NaN   \n",
            "3  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987           NaN   \n",
            "4  sid-841F35F3-ABD1-4ABA-B8AD-28581544A987      1.075431   \n",
            "\n",
            "                                 resourceId                      end  \\\n",
            "0  sid-C1BCD679-E133-4F46-9956-013E1F9E0BD1  2019-04-30T19:19:10.183   \n",
            "1  sid-66F243A5-4165-4803-805B-A5F6BB41B476  2019-04-30T19:19:10.183   \n",
            "2  sid-66F243A5-4165-4803-805B-A5F6BB41B476  2019-04-30T19:19:10.183   \n",
            "3  sid-66F243A5-4165-4803-805B-A5F6BB41B476  2019-04-30T19:19:10.183   \n",
            "4  sid-C1BCD679-E133-4F46-9956-013E1F9E0BD1  2019-05-02T12:28:14.988   \n",
            "\n",
            "                     start  \n",
            "0  2019-04-30T19:16:51.439  \n",
            "1  2019-04-30T19:19:10.183  \n",
            "2  2019-04-30T19:19:10.183  \n",
            "3  2019-04-30T19:19:10.183  \n",
            "4  2019-05-02T12:25:40.126  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now correcting the timestamp values in the above event log\n",
        "df['start'] = pd.to_datetime(df['start'])\n",
        "df['end'] = pd.to_datetime(df['end'])\n",
        "\n",
        "# remove all the extra columns other than the following\n",
        "df = df[['caseid', 'activity', 'resource', 'start', 'end']]\n",
        "print(df.head())\n",
        "# now we have a data frame with only the required information for analysis and evaluation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u61qH_84kS6z",
        "outputId": "1bc797ed-baf6-4d51-8f90-58c82788ed92"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   caseid activity    resource                   start                     end\n",
            "0    5320   Task_1  Resource_1 2019-04-30 19:16:51.439 2019-04-30 19:19:10.183\n",
            "1    5320   Task_2  Resource_2 2019-04-30 19:19:10.183 2019-04-30 19:19:10.183\n",
            "2    5320   Task_3  Resource_2 2019-04-30 19:19:10.183 2019-04-30 19:19:10.183\n",
            "3    5320   Task_4  Resource_2 2019-04-30 19:19:10.183 2019-04-30 19:19:10.183\n",
            "4    5320   Task_5  Resource_1 2019-05-02 12:25:40.126 2019-05-02 12:28:14.988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second stage of preprocessing the event log involves extracting the prefixes for each case"
      ],
      "metadata": {
        "id": "nYQgAKuYm1rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the prefixes of each case in a an event log and create a new dataframe\n",
        "import pandas as pd\n",
        "\n",
        "def extract_prefixes(event_log):\n",
        "    \"\"\"\n",
        "    Extracts prefixes of each case in an event log.\n",
        "\n",
        "    Args:\n",
        "        event_log: DataFrame containing the event log.\n",
        "            It should have columns for case ID and activity name.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with prefixes for each case.\n",
        "    \"\"\"\n",
        "\n",
        "    # Assuming 'case_id' and 'activity' are column names for case ID and activity\n",
        "    all_prefixes = []\n",
        "    for case_id, group in event_log.groupby('caseid'):\n",
        "        # Sort the group by start time\n",
        "        group = group.sort_values(by='start')\n",
        "        for i in range(1, len(group) + 1):\n",
        "            prefix = group['activity'][:i].tolist()\n",
        "            prefix_len = len(prefix)  # Calculate prefix length\n",
        "            # Get the row corresponding to the current prefix\n",
        "            prefix_row = group.iloc[i - 1].copy()\n",
        "            # Add prefix and prefix_len as new columns\n",
        "            prefix_row['prefix'] = prefix\n",
        "            prefix_row['prefix_len'] = prefix_len\n",
        "            all_prefixes.append(prefix_row)\n",
        "\n",
        "    return pd.DataFrame(all_prefixes)\n",
        "\n",
        "# Assuming 'df' is your event log DataFrame\n",
        "prefix_df = extract_prefixes(df)\n",
        "print(prefix_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmktWNYZmE4I",
        "outputId": "6c861477-971e-400f-e022-12184d57ac9c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       caseid activity    resource                   start  \\\n",
            "69399       0   Task_8  Resource_4 2019-03-25 09:00:00.000   \n",
            "69400       0   Task_1  Resource_5 2019-03-25 09:01:41.348   \n",
            "69401       0   Task_2  Resource_2 2019-03-25 09:04:13.469   \n",
            "69402       0   Task_3  Resource_2 2019-03-25 09:04:13.469   \n",
            "69403       0   Task_4  Resource_2 2019-03-25 09:04:13.469   \n",
            "...       ...      ...         ...                     ...   \n",
            "48406    9999   Task_4  Resource_2 2019-05-31 20:45:20.381   \n",
            "48407    9999   Task_9  Resource_4 2019-06-04 17:20:51.178   \n",
            "48408    9999   Task_5  Resource_5 2019-06-05 13:52:33.049   \n",
            "48409    9999   Task_6  Resource_3 2019-06-05 13:55:46.681   \n",
            "48410    9999   Task_7  Resource_1 2019-06-05 15:44:52.696   \n",
            "\n",
            "                          end  \\\n",
            "69399 2019-03-25 09:01:41.348   \n",
            "69400 2019-03-25 09:04:13.469   \n",
            "69401 2019-03-25 09:04:13.469   \n",
            "69402 2019-03-25 09:04:13.469   \n",
            "69403 2019-03-25 09:04:13.469   \n",
            "...                       ...   \n",
            "48406 2019-05-31 20:45:20.381   \n",
            "48407 2019-06-04 17:24:54.263   \n",
            "48408 2019-06-05 13:55:46.681   \n",
            "48409 2019-06-05 13:56:48.722   \n",
            "48410 2019-06-05 15:47:39.333   \n",
            "\n",
            "                                                  prefix  prefix_len  \n",
            "69399                                           [Task_8]           1  \n",
            "69400                                   [Task_8, Task_1]           2  \n",
            "69401                           [Task_8, Task_1, Task_2]           3  \n",
            "69402                   [Task_8, Task_1, Task_2, Task_3]           4  \n",
            "69403           [Task_8, Task_1, Task_2, Task_3, Task_4]           5  \n",
            "...                                                  ...         ...  \n",
            "48406           [Task_8, Task_1, Task_2, Task_3, Task_4]           5  \n",
            "48407   [Task_8, Task_1, Task_2, Task_3, Task_4, Task_9]           6  \n",
            "48408  [Task_8, Task_1, Task_2, Task_3, Task_4, Task_...           7  \n",
            "48409  [Task_8, Task_1, Task_2, Task_3, Task_4, Task_...           8  \n",
            "48410  [Task_8, Task_1, Task_2, Task_3, Task_4, Task_...           9  \n",
            "\n",
            "[83906 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZXBNcWFnQkA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}